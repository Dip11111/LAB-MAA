{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Section 4 & 5: Experiments and pseudo-experiments</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housekeeping and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "import scipy \n",
    "from scipy.linalg import eigh, cholesky\n",
    "from scipy.stats import norm\n",
    "import linearmodels.panel as lmp\n",
    "from pylab import plot, show, axis, subplot, xlabel, ylabel, grid\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we simulate some data to analyze the potential impact of a randomized controlled experiment (RCT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>p</th>\n",
       "      <th>T</th>\n",
       "      <th>cl</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.008144</td>\n",
       "      <td>-0.008738</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>12.349293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.854146</td>\n",
       "      <td>2.310364</td>\n",
       "      <td>1.127331</td>\n",
       "      <td>0.500025</td>\n",
       "      <td>0.500019</td>\n",
       "      <td>2.872425</td>\n",
       "      <td>18.613529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.178571</td>\n",
       "      <td>-7.917647</td>\n",
       "      <td>-4.620694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-55.876786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.235215</td>\n",
       "      <td>-1.548037</td>\n",
       "      <td>-0.743720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.225728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.011478</td>\n",
       "      <td>-0.025907</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>12.327379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.240057</td>\n",
       "      <td>1.544319</td>\n",
       "      <td>0.769077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.710598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.124257</td>\n",
       "      <td>8.164376</td>\n",
       "      <td>4.177833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>77.801101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 X1            X2            X3             p             T  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -0.008144     -0.008738      0.008113      0.500000      0.502500   \n",
       "std        1.854146      2.310364      1.127331      0.500025      0.500019   \n",
       "min       -7.178571     -7.917647     -4.620694      0.000000      0.000000   \n",
       "25%       -1.235215     -1.548037     -0.743720      0.000000      0.000000   \n",
       "50%       -0.011478     -0.025907     -0.000548      0.500000      1.000000   \n",
       "75%        1.240057      1.544319      0.769077      1.000000      1.000000   \n",
       "max        7.124257      8.164376      4.177833      1.000000      1.000000   \n",
       "\n",
       "                 cl             y  \n",
       "count  10000.000000  10000.000000  \n",
       "mean       5.500000     12.349293  \n",
       "std        2.872425     18.613529  \n",
       "min        1.000000    -55.876786  \n",
       "25%        3.000000     -0.225728  \n",
       "50%        5.500000     12.327379  \n",
       "75%        8.000000     24.710598  \n",
       "max       10.000000     77.801101  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment parameters\n",
    "np.random.seed(123) #set seed\n",
    "nsize = 10000\n",
    "\n",
    "\n",
    "# variance-covariance matrix (simetric)\n",
    "cov = np.array([\n",
    "        [  3.40, -2.75, -2.00],\n",
    "        [ -2.75,  5.50,  1.50],\n",
    "        [ -2.00,  1.50,  1.25]\n",
    "    ])\n",
    "\n",
    "# correlated variables in dataset form (mean zero)\n",
    "X = norm.rvs(size=(3, nsize))\n",
    "evals, evecs = eigh(cov)\n",
    "c = np.dot(evecs, np.diag(np.sqrt(evals)))\n",
    "Xc = np.dot(c, X)\n",
    "Xc = Xc.transpose()\n",
    "Xc = pd.DataFrame(Xc, columns=['X1','X2','X3'])\n",
    "\n",
    "#time periods and treatment asignment \n",
    "Xc['p'] = 1\n",
    "Xc.loc[0:4999,'p'] = 0\n",
    "Xc['T'] = np.random.binomial(1, 0.5, size=10000)\n",
    "\n",
    "#grouping variable\n",
    "Xc['cl']=1\n",
    "Xc.loc[500:999,'cl']=2\n",
    "Xc.loc[1000:1499,'cl']=3\n",
    "Xc.loc[1500:1999,'cl']=4\n",
    "Xc.loc[2000:2499,'cl']=5\n",
    "Xc.loc[2500:2999,'cl']=6\n",
    "Xc.loc[3000:3499,'cl']=7\n",
    "Xc.loc[3500:3999,'cl']=8\n",
    "Xc.loc[4000:4499,'cl']=9\n",
    "Xc.loc[4500:4999,'cl']=10\n",
    "Xc.loc[5500:5999,'cl']=2\n",
    "Xc.loc[6000:6499,'cl']=3\n",
    "Xc.loc[6500:6999,'cl']=4\n",
    "Xc.loc[7000:7499,'cl']=5\n",
    "Xc.loc[7500:7999,'cl']=6\n",
    "Xc.loc[8000:8499,'cl']=7\n",
    "Xc.loc[8500:8999,'cl']=8\n",
    "Xc.loc[9000:9499,'cl']=9\n",
    "Xc.loc[9500:9999,'cl']=10\n",
    "\n",
    "#outcome variable\n",
    "Xc['y'] = 10*(1+Xc['X1']) + 10*(Xc['X2']+Xc['T']*Xc['p']) + Xc['X3'] \n",
    "\n",
    "#data description\n",
    "Xc.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Controlled Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can estimate the sample size needed for a given effect (power analysis). In this example we estimate a sample size for a standarized effect of 0.2, a signficance of 95% (alpha=0.05), and power of 0.9 (chances of a false negative are 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 526.000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# parameters for power analysis \n",
    "effect = 0.2\n",
    "alpha = 0.05\n",
    "power = 0.9\n",
    "\n",
    "# perform power analysis \n",
    "analysis = TTestIndPower()\n",
    "result = analysis.solve_power(effect, power = power, nobs1= None, ratio = 1.0, alpha = alpha)\n",
    "print('Sample Size: %.3f' % round(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the data generated we can estimate the treatment effect using OLS and creating some additional variables as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.074\n",
      "Model:                            OLS   Adj. R-squared:                  0.073\n",
      "Method:                 Least Squares   F-statistic:                     396.7\n",
      "Date:                Mon, 07 Nov 2022   Prob (F-statistic):           5.23e-85\n",
      "Time:                        18:07:05   Log-Likelihood:                -21576.\n",
      "No. Observations:                5000   AIC:                         4.316e+04\n",
      "Df Residuals:                    4998   BIC:                         4.317e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.8951      0.363     27.267      0.000       9.184      10.607\n",
      "T             10.2018      0.512     19.918      0.000       9.198      11.206\n",
      "==============================================================================\n",
      "Omnibus:                        0.154   Durbin-Watson:                   1.930\n",
      "Prob(Omnibus):                  0.926   Jarque-Bera (JB):                0.175\n",
      "Skew:                          -0.012   Prob(JB):                        0.916\n",
      "Kurtosis:                       2.983   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#post-test\n",
    "y = Xc.loc[5000:9999,'y']\n",
    "X = Xc.loc[5000:9999,'T']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.058\n",
      "Model:                            OLS   Adj. R-squared:                  0.058\n",
      "Method:                 Least Squares   F-statistic:                     205.5\n",
      "Date:                Mon, 07 Nov 2022   Prob (F-statistic):          2.45e-129\n",
      "Time:                        18:07:11   Log-Likelihood:                -43129.\n",
      "No. Observations:               10000   AIC:                         8.627e+04\n",
      "Df Residuals:                    9996   BIC:                         8.629e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.6617      0.362     26.657      0.000       8.951      10.372\n",
      "p              0.2334      0.512      0.456      0.649      -0.771       1.238\n",
      "T              0.0407      0.511      0.080      0.936      -0.961       1.042\n",
      "dd            10.1611      0.723     14.060      0.000       8.744      11.578\n",
      "==============================================================================\n",
      "Omnibus:                        0.648   Durbin-Watson:                   1.948\n",
      "Prob(Omnibus):                  0.723   Jarque-Bera (JB):                0.651\n",
      "Skew:                          -0.020   Prob(JB):                        0.722\n",
      "Kurtosis:                       2.996   Cond. No.                         6.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#pre-post test\n",
    "y=Xc['y']\n",
    "Xc['dd']= Xc['p']*Xc['T']\n",
    "X=Xc[['p','T','dd']]\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results2 = model.fit()\n",
    "print(results2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.058\n",
      "Model:                            OLS   Adj. R-squared:                  0.058\n",
      "Method:                 Least Squares   F-statistic:                     302.7\n",
      "Date:                Mon, 07 Nov 2022   Prob (F-statistic):           2.37e-09\n",
      "Time:                        18:16:11   Log-Likelihood:                -43129.\n",
      "No. Observations:               10000   AIC:                         8.627e+04\n",
      "Df Residuals:                    9996   BIC:                         8.629e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.6617      0.379     25.484      0.000       8.919      10.405\n",
      "p              0.2334      0.407      0.574      0.566      -0.564       1.031\n",
      "T              0.0407      0.503      0.081      0.935      -0.946       1.027\n",
      "dd            10.1611      0.761     13.349      0.000       8.669      11.653\n",
      "==============================================================================\n",
      "Omnibus:                        0.648   Durbin-Watson:                   1.948\n",
      "Prob(Omnibus):                  0.723   Jarque-Bera (JB):                0.651\n",
      "Skew:                          -0.020   Prob(JB):                        0.722\n",
      "Kurtosis:                       2.996   Cond. No.                         6.87\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "#clustered standard errors\n",
    "results3 = model.fit(cov_type=\"cluster\", cov_kwds={'groups': Xc['cl']})\n",
    "print(results3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **charls.csv** we will estimate basic difference in diference estimator and instrumental variables. The intervention is a public pension (*nrps*) and the outcome variable is retirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bnrps</th>\n",
       "      <th>cesd</th>\n",
       "      <th>child</th>\n",
       "      <th>dnrps</th>\n",
       "      <th>female</th>\n",
       "      <th>hrsusu</th>\n",
       "      <th>hsize</th>\n",
       "      <th>intmonth</th>\n",
       "      <th>married</th>\n",
       "      <th>nrps</th>\n",
       "      <th>retage</th>\n",
       "      <th>retired</th>\n",
       "      <th>schadj</th>\n",
       "      <th>urban</th>\n",
       "      <th>wave</th>\n",
       "      <th>wealth</th>\n",
       "      <th>inid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>21045.000000</td>\n",
       "      <td>2.104500e+04</td>\n",
       "      <td>21045.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.386553</td>\n",
       "      <td>59.610683</td>\n",
       "      <td>8.656878</td>\n",
       "      <td>2.825232</td>\n",
       "      <td>0.259111</td>\n",
       "      <td>0.521026</td>\n",
       "      <td>2.548166</td>\n",
       "      <td>3.585222</td>\n",
       "      <td>7.511143</td>\n",
       "      <td>0.907674</td>\n",
       "      <td>0.519078</td>\n",
       "      <td>1.280969</td>\n",
       "      <td>0.204942</td>\n",
       "      <td>4.162414</td>\n",
       "      <td>0.206652</td>\n",
       "      <td>1.909385</td>\n",
       "      <td>6.783959e+03</td>\n",
       "      <td>12747.082870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.016106</td>\n",
       "      <td>51.905928</td>\n",
       "      <td>6.307677</td>\n",
       "      <td>1.372179</td>\n",
       "      <td>0.438157</td>\n",
       "      <td>0.499570</td>\n",
       "      <td>1.757182</td>\n",
       "      <td>1.720136</td>\n",
       "      <td>0.865851</td>\n",
       "      <td>0.289492</td>\n",
       "      <td>0.499648</td>\n",
       "      <td>3.830963</td>\n",
       "      <td>0.403669</td>\n",
       "      <td>3.540039</td>\n",
       "      <td>0.404914</td>\n",
       "      <td>0.817975</td>\n",
       "      <td>5.453065e+04</td>\n",
       "      <td>7769.025809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.648450e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>5176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>13314.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>74.875404</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.025352</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.800000e+03</td>\n",
       "      <td>19650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.123964</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.040000e+06</td>\n",
       "      <td>25403.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age         bnrps          cesd         child         dnrps  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean      59.386553     59.610683      8.656878      2.825232      0.259111   \n",
       "std        9.016106     51.905928      6.307677      1.372179      0.438157   \n",
       "min       20.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       52.000000      0.000000      4.000000      2.000000      0.000000   \n",
       "50%       59.000000     60.000000      7.000000      3.000000      0.000000   \n",
       "75%       65.000000     74.875404     12.000000      4.000000      1.000000   \n",
       "max       95.000000    300.000000     30.000000     10.000000      1.000000   \n",
       "\n",
       "             female        hrsusu         hsize      intmonth       married  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean       0.521026      2.548166      3.585222      7.511143      0.907674   \n",
       "std        0.499570      1.757182      1.720136      0.865851      0.289492   \n",
       "min        0.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "25%        0.000000      0.000000      2.000000      7.000000      1.000000   \n",
       "50%        1.000000      3.401197      3.000000      7.000000      1.000000   \n",
       "75%        1.000000      4.025352      5.000000      8.000000      1.000000   \n",
       "max        1.000000      5.123964     16.000000     12.000000      1.000000   \n",
       "\n",
       "               nrps        retage       retired        schadj         urban  \\\n",
       "count  21045.000000  21045.000000  21045.000000  21045.000000  21045.000000   \n",
       "mean       0.519078      1.280969      0.204942      4.162414      0.206652   \n",
       "std        0.499648      3.830963      0.403669      3.540039      0.404914   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      4.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      8.000000      0.000000   \n",
       "max        1.000000     51.000000      1.000000     16.000000      1.000000   \n",
       "\n",
       "               wave        wealth          inid  \n",
       "count  21045.000000  2.104500e+04  21045.000000  \n",
       "mean       1.909385  6.783959e+03  12747.082870  \n",
       "std        0.817975  5.453065e+04   7769.025809  \n",
       "min        1.000000 -1.648450e+06      1.000000  \n",
       "25%        1.000000  1.000000e+02   5176.000000  \n",
       "50%        2.000000  1.000000e+03  13314.000000  \n",
       "75%        3.000000  6.800000e+03  19650.000000  \n",
       "max        3.000000  1.040000e+06  25403.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charls = pd.read_csv('../data/charls.csv')\n",
    "charls.dropna(inplace=True)\n",
    "charls.reset_index(drop=True, inplace=True)\n",
    "\n",
    "charls.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                retired   R-squared:                       0.124\n",
      "Model:                            OLS   Adj. R-squared:                  0.124\n",
      "Method:                 Least Squares   F-statistic:                     595.8\n",
      "Date:                Mon, 07 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        21:27:55   Log-Likelihood:                -9376.5\n",
      "No. Observations:               21045   AIC:                         1.876e+04\n",
      "Df Residuals:                   21039   BIC:                         1.881e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.6142      0.024    -26.073      0.000      -0.660      -0.568\n",
      "married       -0.0745      0.009     -7.927      0.000      -0.093      -0.056\n",
      "female         0.1045      0.005     19.861      0.000       0.094       0.115\n",
      "age            0.0143      0.000     46.946      0.000       0.014       0.015\n",
      "hsize         -0.0002      0.002     -0.156      0.876      -0.003       0.003\n",
      "nrps          -0.0260      0.005     -4.979      0.000      -0.036      -0.016\n",
      "==============================================================================\n",
      "Omnibus:                     3404.726   Durbin-Watson:                   1.451\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5359.254\n",
      "Skew:                           1.230   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.254   Cond. No.                         559.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "Xa=charls[['married','female','age','hsize','nrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "\n",
    "model = sm.OLS(ya, Xa)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumental Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we re-estimate the natural experiment design but using instrumental variables, so we explore the LATE effect, instead of ATE effect. The instrument is implementation date of the policy (*dnrps*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015658522589718407"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xf=charls[['married','female','age','dnrps']]\n",
    "yf=charls['nrps']\n",
    "Xf = sm.add_constant(Xf)\n",
    "model = sm.OLS(yf, Xf)\n",
    "first = model.fit()\n",
    "charls['pnrps']=first.predict(Xf)\n",
    "\n",
    "Xa=charls[['married','female','age','hsize','pnrps']]\n",
    "ya=charls['retired']\n",
    "Xa = sm.add_constant(Xa)\n",
    "model = sm.OLS(ya, Xa)\n",
    "results = model.fit()\n",
    "\n",
    "results.params['pnrps']/first.params['dnrps']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false
   },
   "source": [
    "## Event study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the simulated data from the first section, we will explore the estimator for event study design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>T</th>\n",
       "      <th>cl</th>\n",
       "      <th>y</th>\n",
       "      <th>Tc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026132</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>15.016427</td>\n",
       "      <td>0.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.876621</td>\n",
       "      <td>2.335915</td>\n",
       "      <td>0.299228</td>\n",
       "      <td>2.872569</td>\n",
       "      <td>18.811681</td>\n",
       "      <td>2.842524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-7.178571</td>\n",
       "      <td>-7.798972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-51.895660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.232056</td>\n",
       "      <td>-1.585591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.357421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.024851</td>\n",
       "      <td>-0.029248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>14.878440</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.275864</td>\n",
       "      <td>1.557381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>27.584598</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.124257</td>\n",
       "      <td>7.803660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>77.801101</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2            T           cl            y  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      0.026132    -0.024901     0.099400     5.500000    15.016427   \n",
       "std       1.876621     2.335915     0.299228     2.872569    18.811681   \n",
       "min      -7.178571    -7.798972     0.000000     1.000000   -51.895660   \n",
       "25%      -1.232056    -1.585591     0.000000     3.000000     2.357421   \n",
       "50%       0.024851    -0.029248     0.000000     5.500000    14.878440   \n",
       "75%       1.275864     1.557381     0.000000     8.000000    27.584598   \n",
       "max       7.124257     7.803660     1.000000    10.000000    77.801101   \n",
       "\n",
       "                Tc  \n",
       "count  5000.000000  \n",
       "mean      0.942800  \n",
       "std       2.842524  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max      10.000000  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xe = Xc.loc[5000:9999]\n",
    "Xe = Xe[['X1','X2','T','cl','y']]\n",
    "Xe.reset_index(drop=True, inplace=True)\n",
    "Xe.loc[0:3999,'T'] = 0\n",
    "Xe['Tc']= Xe['cl']*Xe['T']\n",
    "Xe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.939\n",
      "Model:                            OLS   Adj. R-squared:                  0.939\n",
      "Method:                 Least Squares   F-statistic:                 1.926e+04\n",
      "Date:                Mon, 07 Nov 2022   Prob (F-statistic):               0.00\n",
      "Time:                        21:54:45   Log-Likelihood:                -14770.\n",
      "No. Observations:                5000   AIC:                         2.955e+04\n",
      "Df Residuals:                    4995   BIC:                         2.958e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         16.2350      0.148    109.898      0.000      15.945      16.525\n",
      "Tc             0.7433      0.026     28.507      0.000       0.692       0.794\n",
      "cl            -0.3485      0.026    -13.506      0.000      -0.399      -0.298\n",
      "X1             9.4038      0.046    206.528      0.000       9.315       9.493\n",
      "X2             9.9754      0.037    272.776      0.000       9.904      10.047\n",
      "==============================================================================\n",
      "Omnibus:                    22277.685   Durbin-Watson:                   1.881\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              624.299\n",
      "Skew:                           0.188   Prob(JB):                    2.72e-136\n",
      "Kurtosis:                       1.310   Cond. No.                         14.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ye = Xe['y']\n",
    "Xe = Xe[['Tc','cl','X1','X2']]\n",
    "Xe = sm.add_constant(Xe)\n",
    "model = sm.OLS(ye, Xe)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">**Tarea 3**</font>\n",
    "\n",
    "<u> *Instrucciones* </u>\n",
    "\n",
    "Los resultados de los ejericicios propuestos se deben entregar como un notebook por correo electronico a *juan.caro@uni.lu* el dia 25/11 hasta las 21:00. \n",
    "\n",
    "Es importante considerar que el código debe poder ejecutarse en cualquier computadora con la data original del repositorio. Recordar la convencion para el nombre de archivo ademas de incluir en su documento titulos y encabezados por seccion. La unica data real a utilizar en parte de esta tarea es **charls.csv**. El resto de la data de la tarea debe ser generada a partir de las caracteristicas que se especifican. Las variables en **charls.csv** tienen la siguiente descripcion:\n",
    "\n",
    "- inid: identificador unico\n",
    "- wave: periodo de la encuesta (1-3)\n",
    "- cesd: puntaje en la escala de salud mental (0-30)\n",
    "- child: numero de hijos\n",
    "- drinkly: bebio alcohol en el ultimo mes (binario)\n",
    "- hrsusu: horas promedio trabajo semanal\n",
    "- hsize: tamano del hogar\n",
    "- intmonth: mes en que fue encuestado/a (1-12)\n",
    "- married: si esta casado/a (binario)\n",
    "- retired: si esta pensionado/a (binario)\n",
    "- schadj: años de escolaridad\n",
    "- urban: zona urbana (binario)\n",
    "- wealth: riqueza neta (miles RMB)\n",
    "- age: edad al entrar a la encuesta (no varia entre periodos)\n",
    "- bnrps: monto de pension publica (en RMB/mes)\n",
    "- dnrps: pension implementada en la provincia (binaria)\n",
    "- retage: fecha esperada de retiro (años desde la fecha de encuenta)\n",
    "- female: genero del encuestado\n",
    "- nrps: recibe pension publica\n",
    "\n",
    "Preguntas:\n",
    "\n",
    "Parte 1 - Experimentos\n",
    "\n",
    "Deben conceptualizar un experimento con el objetivo de estudiar posibles incentivos o estrategias para incrementar la asistencia a clases en estudiantes universitarios de la UdeC. El outcome del tratamiento es la proporcion promedio de estudiantes que asisten a clases. Todos los elementos del experimento deben ser definidos, respondiendo a las siguientes preguntas: \n",
    "\n",
    "1. Asumiendo la existencia de recursos disponibles e implementacion a nivel de estudiante, sugiera un tratamiento que pueda ser testeado a traves de un experimento aleatorizado controlado. Sea especifico en cuanto a los detalles del tratamiento (costos, materiales, duracion, etcetera).\n",
    "\n",
    "2. Defina los grupos de tratamiento y control para implementar su experimento. Describa en detalle el mecanismo de asignacion aleatorio que permite la comparacion entre grupos.\n",
    "\n",
    "3. Que metodo considera el mas apropiado para la estimacion del efecto promedio? (pre-test, pre-post test, Salomon 4 group). Justifique su respuesta en base a las ventajas y desventajas de cada metodo. \n",
    "\n",
    "4. Ahora suponga que no es posible implementar un experimento a nivel de estudiante, sino a nivel de clase. Como ajustaria los elementos de su experimento para poder ser implementado a nivel de cluster? Sea especifico respecto tanto del tratamiento como del metodo de asignacion aleatorio y potencial comparacion entre grupos de tratamiento y control.\n",
    "\n",
    "5. Suponga que en vez de un experimento, se planifica que sea un programa implementado a nivel de toda la Universidad. Como ajustaria los elementos descritos anteriormente para poder comparar el efecto de la intervencion.  \n",
    "\n",
    "Parte 2 - Estimacion de efectos promedio de tratamiento (data simulada)\n",
    "\n",
    "6. A partir de sus respuestas en Parte 1, genere data para 40 grupos (considere cada grupo como una clase) con 50 estudiantes cada uno (asuma que los estudiantes son asignados aleatoriamente a cada clase). Cada estudiante debe tener data de asistencia en un periodo, generando una variable binaria aleatoria talque la asistencia promedio a traves de todos los grupos es de 80%.\n",
    "\n",
    "7. Genere un mecanismo de asignacion aleatorio a nivel de estudiante y muestre que en la data generada permite que ambos grupos (tratamiento y control) tienen una asistencia promedio comparable.\n",
    "\n",
    "8. Genere un tratamiento que imcrementa la participacion en el grupo de tratamiento en 10 puntos porcentuales. Ademas en la data posterior al experimento, asuma que la participacion promedio cayo a 75%. Estime el efecto promedio del tratamiento usando solo post-test.\n",
    "\n",
    "9. Estime el efecto promedio del tratamiento usando pre-post test con la data generada. Muestre que el efecto es equivalente usando ambos metodos.\n",
    "\n",
    "10. Estime el efecto ajustando los errores estandar por cluster (la variable grupo representa cada clase). Cual es la diferencia entre ambas estimaciones? Explique porque es esperable (o no) encontrar diferencias entre ambos metodos.\n",
    "\n",
    "Parte 3 - Experimentos naturales \n",
    "\n",
    "Usando la data **charls.csv**, responda las siguientes preguntas relativas a experimentos naturales.\n",
    "\n",
    "11. Simule un experimento natural (e.g. intervencion de politica publica) tal que se reduce la proporcion de individuos con 3 hijos o mas que declaran beber alcohol en el tercer periodo a la mitad. Para ello, genere una variable de tratamiento (todos los individuos con mas de 2 hijos son parte de la intervencion), y una nueva variable llamada *sdrinlky*, talque es identica a *drinkly* en los periodos 1 y 2 , pero sustituya los valores aleatoriamente en el periodo 3 para generar el efecto esperado.\n",
    "\n",
    "12. Estime el efecto del tratamiento usando diferencias en diferencias, comparando entre los periodos 2 y 3. \n",
    "\n",
    "13. Compare el efecto del tratamiento generando grupos pseudo-equivalentes, en particular entre individuos solo con 3 hijos (tratamiento) y 2 hijos (control). \n",
    "\n",
    "14. Estime el efecto anterior usando la variable *married* como instrumento para determinar el efecto del tratamiento en la pregunta 12. Como se interpreta el efecto en este caso?\n",
    "\n",
    "15. Finalmente, asuma que la intervencion se implementa en todos los individuos. Genere una nueva variable de tratamiento un nueva variable llamada *tdrinkly* donde el efecto es una reduccion de 50% en la prevalencia de consumo de alcohol en toda la poblacion en el tercer periodo (identica a *drinkly* en los periodos 1 y 2). Genere una variable *cdrinkly* que es identica a *drinkly* en los periodos 1 y 2 y use la informacion de ambos periodos para predicir el valor esperado de *drinkly* en el tercer periodo, estos seran los valores de *cdrinkly* en el periodo 3 (contrafactual). Finalmente, estime el efecto de la intervencion en toda la poblacion comparando entre *tdrinkly* (datos reales) versus *cdrinkly* contrafactual.   "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
