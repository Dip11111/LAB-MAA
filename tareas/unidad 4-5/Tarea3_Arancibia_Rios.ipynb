{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">Tarea 3 - César Arancibia, Francisco Ríos</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn\n",
    "import scipy \n",
    "from scipy.linalg import eigh, cholesky\n",
    "from scipy.stats import norm\n",
    "import linearmodels.panel as lmp\n",
    "from pylab import plot, show, axis, subplot, xlabel, ylabel, grid\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Asumiendo la existencia de recursos disponibles e implementacion a nivel de estudiante, sugiera un tratamiento que pueda ser testeado a traves de un experimento aleatorizado controlado. Sea especifico en cuanto a los detalles del tratamiento (costos, materiales, duracion, etcetera).\n",
    "\n",
    "En la búsqueda de medios y tratamientos capaces de ser aplicados a estudiantes específicos, se hace dificil la tarea de evitar la contaminación de los datos. Puesto que no son muchas las variables a controlar que no sean comentadas entre estudiantes y que descubran si son parte del grupo controlado. La principal idea del grupo de trabajo se basa en la aplicación de estímulos positivos para la participación y asistencia del alumno, no de aplicar castigos o medios obligatorios. Por ejemplo, una prueba o test por clase obligaría al estudiante a ir, pero no se puede aplicar a unos estudiantes si y otros no aleatoriamente. El mismo concepto eliminó la posible idea de aplicar buses de acercamiento para los estudiantes, desayunos en caso de que fuesen clases en la mañana, etc. En este sentido, nace la idea de un experimento sencillo para aumentar el porcentaje de asistencia individual con tal de aumentar la proporción de estudiantes que asisten a sus clases. \n",
    "El experimento se basa en la aplicación de estímulos verbales positivos en las interacciones con el profesor.  Este tratamiento tendría un costo relativo a cero, y la probabilidad de que los alumnos “descubrieran” que son parte de un tratamiento es bastante baja.\n",
    "¿A qué se refiere este tratamiento? A nivel de clase, los alumnos serían seleccionados aleatoriamente con tal de evaluar su asistencia, y clase a clase el profesor le felicitaría o mencionaría que su desempeño es positivo, destacando su presencia. Esto no debería significar ninguna diferencia o preferencia en notas, décimas, actividades o aspectos académicos. Sólo un estímulo positivo emocional. La clase a evaluar debe delimitar correctamente el horario, y no variar ni en este aspecto ni en la cantidad de créditos o importancia relativa en la carrera, de evaluarse distintas asignaturas.\n",
    "La variable dependiente sería, como específica la instrucción, la asistencia promedio a la asignatura del estudiante. \n",
    "En este sentido, las variables a evaluar por alumno serían:\n",
    "Si reciben reforzamiento positivo por participación/asistencia a clase \n",
    "Cuantas veces reciben tratamiento en el periodo de estudio \n",
    "Su porcentaje de asistencia a clase en general \n",
    "Cantidad de horas de clase que tiene en el día de la aplicación del tratamiento\n",
    "Cantidad de días a la semana en que tiene clases\n",
    "Vive con su familia o es arrendatario. \n",
    "Distancia de su casa a la Universidad\n",
    "Primera nota en la asignatura\n",
    "Promedio notas en la asignatura\n",
    "Año cursado \n",
    "Cantidad de ramos reprobados hasta el momento\n",
    "Más un error fijo por individuo, debido a factores no observables tales como: \n",
    "Cantidad de amigos en la Universidad\n",
    "Cantidad de amigos en la asignatura \n",
    "Cercanía con su grupo social\n",
    "Apreciación personal de su grupo social\n",
    "Importancia que se le da a la asignatura\n",
    "El experimento debe ser aplicado durante una cantidad fija de tiempo, como por ejemplo un semestre, con tal de evaluar los resultados en un lapso de tiempo significativo. Ya que una semana, por ejemplo, no demostraría ningún resultado importante. La proporción promedio de estudiantes que asisten a clase debería reflejar de cierta manera la importancia de los estímulos positivos en la vida de los alumnos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Defina los grupos de tratamiento y control para implementar su experimento. Describa en detalle el mecanismo de asignacion aleatorio que permite la comparacion entre grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta sería una asignación y selección aleatoria, en la que se espera que las variables sociales jueguen un rol importante. Una selección equitativa de estudiantes en el grupo control y en el grupo tratamiento, con variables similares, podría dejar ver la causalidad del reforzamiento positivo. Además, se puede extrapolar el resultado para sacar un contrafactual de los alumnos similares pero que no fueron afectados por el tratamiento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Que metodo considera el mas apropiado para la estimacion del efecto promedio? (pre-test, pre-post test, Salomon 4 group). Justifique su respuesta en base a las ventajas y desventajas de cada metodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso sería favorable el método de Solomon. Así no se perdería información en el tiempo, ya que la aplicación del tratamiento no es un momento específico sino una constante aplicación. Entonces, los cuatro grupos podrían ser comparados en función de la consistencia de los resultados. Por ejemplo, se estudiaría a los alumnos antes del tratamiento con tal de ver su participación y calidad de respuesta en la asignatura. Se aplicaría el tratamiento y luego se evaluaría un resultado posterior. El segundo grupo solo se vería afectado por los análisis previos y posteriores al tratamiento, pero sin pasar por este. Luego un tercer grupo no se evaluaría antes de, y un cuarto grupo solo vería el post test. Este método es apreciado por el grupo de trabajo en cuanto a la aplicación de este experimento al reducir los posibles efectos secundarios de la prueba previa al tratamiento. Además, permite controlar que la satisfacción, participación y calidad de los estudiantes en la asignatura sea observada por sí sola en cuatro escenarios completos.\n",
    "Como todos los alumnos se podrían ver como de igual interés, quizá la aplicación de un método simple tradicional haría perder ciertos resultados del experimento, haciéndolo ineficaz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ahora suponga que no es posible implementar un experimento a nivel de estudiante, sino a nivel de clase. Como ajustaria los elementos de su experimento para poder ser implementado a nivel de cluster? Sea especifico respecto tanto del tratamiento como del metodo de asignacion aleatorio y potencial comparacion entre grupos de tratamiento y control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, las variables discretas se transforman en binarias y las binarias no sé estandarizan cómo las demás para asegurar la cercanía entre individuos del grupo.  La parte importante será asegurar la correlación entre los miembros entre el grupo pero la diferencia estadística entre los grupos.  El experimento verá cambiado su enfoque más que nada en la forma de entregar el reforzamiento positivo a nivel grupal y se podía añadir preguntar por ciertas personas si faltan. Cosa de demostrar que se nota. Las variables individuales como las notas cambiarán a promedio de notas de todos los estudiantes. Y algunas como de si vive o no solo se debería cambiar a si la mayoría lo hace o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Suponga que en vez de un experimento, se planifica que sea un programa implementado a nivel de toda la Universidad. Cómo ajustar los elementos descritos anteriormente para poder comparar el efecto de la intervención."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sería lo mismo que la aplicación a Clúster. El problema sería que la aplicación del pre y post tratamiento, y el tratamiento tendría mucho más riesgo de ser contaminado por la comunicación. Además, pre y post deberá ser un programa completo a nivel universidad para asegurar la participación para no perder datos a lo largo del tratamiento. Se encontrarían también más problemas a nivel de aplicación, puesto que la heterogeneidad por temas de profesor, facultad y forma de aplicación de los tratamientos podría ser distinto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. A partir de sus respuestas en Parte 1, genere data para 40 grupos (considere cada grupo como una clase) con 50 estudiantes cada uno (asuma que los estudiantes son asignados aleatoriamente a cada clase). Cada estudiante debe tener data de asistencia en un periodo, generando una variable binaria aleatoria talque la asistencia promedio a traves de todos los grupos es de 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A      X  Cl  P\n",
      "0     1  0.436   1  0\n",
      "1     1 -0.599   1  0\n",
      "2     0  0.033   1  0\n",
      "3     1 -0.854   1  0\n",
      "4     0 -0.720   1  0\n",
      "...  ..    ...  .. ..\n",
      "3995  1  0.724  40  1\n",
      "3996  1  0.606  40  1\n",
      "3997  1 -1.290  40  1\n",
      "3998  1  0.789  40  1\n",
      "3999  0  1.961  40  1\n",
      "\n",
      "[4000 rows x 4 columns]\n",
      "                A            X          Cl            P\n",
      "count  4000.00000  4000.000000  4000.00000  4000.000000\n",
      "mean      0.80000    -0.009463    20.50000     0.500000\n",
      "std       0.40005     0.987632    11.54484     0.500063\n",
      "min       0.00000    -3.740000     1.00000     0.000000\n",
      "25%       1.00000    -0.693750    10.75000     0.000000\n",
      "50%       1.00000    -0.014500    20.50000     0.500000\n",
      "75%       1.00000     0.656000    30.25000     1.000000\n",
      "max       1.00000     3.802000    40.00000     1.000000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0);\n",
    "\n",
    "class clase:\n",
    "    def __init__(self,_id):\n",
    "        self._id = _id;\n",
    "    def generar_est(self,cantidad,proporcion):\n",
    "        self.c = cantidad;\n",
    "        self.p = proporcion;\n",
    "        irresponsables = np.sort(np.random.choice([j for j in range(self.c)], round(self.c-(self.c*self.p)), replace=False));\n",
    "        self.g = [];\n",
    "        for j in range(self.c):\n",
    "            if j in irresponsables:\n",
    "                self.aux = estudiante(str(i)+\"_\"+str(j),0);\n",
    "            else:\n",
    "                self.aux = estudiante(str(i)+\"_\"+str(j),1);\n",
    "            self.g.append(self.aux);\n",
    "        return self.g;\n",
    "    \n",
    "class estudiante:\n",
    "    def __init__(self,_id,asistencia):\n",
    "        self._id = _id;\n",
    "        self.a = asistencia;\n",
    "    def return_asist(self):\n",
    "        return self.a;\n",
    "        \n",
    "grupos = [];\n",
    "grupos_val = [];\n",
    "for i in range(40):\n",
    "    cl = clase(i);\n",
    "    aux = cl.generar_est(50,0.8);\n",
    "    grupos.append(aux);\n",
    "    aux2 = [];\n",
    "    for k in range(len(aux)):\n",
    "        aux2.append(aux[k].return_asist());\n",
    "    grupos_val.append(aux2);\n",
    "    \n",
    "#grupos_val = np.array(grupos_val);\n",
    "\n",
    "np.set_printoptions(threshold=np.inf);\n",
    "grupos_val = [item for sub_item in grupos_val for item in sub_item];\n",
    "#print(grupos_val)\n",
    "\n",
    "grupos_val.extend(grupos_val.copy());\n",
    "df = pd.DataFrame(grupos_val,columns=[\"A\"]);\n",
    "\n",
    "ruido = np.around(np.random.normal(loc=0,scale=1,size=4000),decimals=3);\n",
    "df[\"X\"] = ruido;\n",
    "df[\"Cl\"] = 0;\n",
    "df[\"P\"] = 0;\n",
    "df.loc[2000:3999,\"P\"] = 1;\n",
    "#print(df);\n",
    "for i in range(len(df)//2):\n",
    "    df.loc[i,\"Cl\"] = i // 50 + 1;\n",
    "    df.loc[2000+i,\"Cl\"] = i // 50 + 1;\n",
    "print(df);\n",
    "print(df.describe());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Genere un mecanismo de asignacion aleatorio a nivel de estudiante y muestre que en la data generada permite que ambos grupos (tratamiento y control) tienen una asistencia promedio comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A      X  Cl  P  T\n",
      "0     1  0.436   1  0  0\n",
      "1     1 -0.599   1  0  1\n",
      "2     0  0.033   1  0  1\n",
      "3     1 -0.854   1  0  0\n",
      "4     0 -0.720   1  0  1\n",
      "...  ..    ...  .. .. ..\n",
      "3995  1  0.724  40  1  1\n",
      "3996  1  0.606  40  1  0\n",
      "3997  1 -1.290  40  1  1\n",
      "3998  1  0.789  40  1  0\n",
      "3999  0  1.961  40  1  1\n",
      "\n",
      "[4000 rows x 5 columns]\n",
      "                A            X          Cl            P            T\n",
      "count  4000.00000  4000.000000  4000.00000  4000.000000  4000.000000\n",
      "mean      0.80000    -0.009463    20.50000     0.500000     0.500000\n",
      "std       0.40005     0.987632    11.54484     0.500063     0.500063\n",
      "min       0.00000    -3.740000     1.00000     0.000000     0.000000\n",
      "25%       1.00000    -0.693750    10.75000     0.000000     0.000000\n",
      "50%       1.00000    -0.014500    20.50000     0.500000     0.500000\n",
      "75%       1.00000     0.656000    30.25000     1.000000     1.000000\n",
      "max       1.00000     3.802000    40.00000     1.000000     1.000000\n",
      "Asistencia promedio grupo control:\n",
      "0.802\n",
      "Asistencia promedio grupo tratamiento:\n",
      "0.798\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0);\n",
    "opciones = np.sort(np.random.choice([i for i in range(2000)],1000,replace=False));\n",
    "df[\"T\"] = 0;\n",
    "for i in opciones:\n",
    "    df.loc[i,\"T\"] = 1;\n",
    "    df.loc[2000+i,\"T\"] = 1;\n",
    "    \n",
    "print(df);\n",
    "print(df.describe());\n",
    "print(\"Asistencia promedio grupo control:\")\n",
    "print(np.mean(df[\"A\"][df[\"T\"] == 0]));\n",
    "print(\"Asistencia promedio grupo tratamiento:\")\n",
    "print(np.mean(df[\"A\"][df[\"T\"] == 1]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Genere un tratamiento que imcrementa la participacion en el grupo de tratamiento en 10 puntos porcentuales. Ademas en la data posterior al experimento, asuma que la participacion promedio cayo a 75%. Estime el efecto promedio del tratamiento usando solo post-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                A            X          Cl            P            T  \\\n",
      "count  4000.00000  4000.000000  4000.00000  4000.000000  4000.000000   \n",
      "mean      0.80000    -0.009463    20.50000     0.500000     0.500000   \n",
      "std       0.40005     0.987632    11.54484     0.500063     0.500063   \n",
      "min       0.00000    -3.740000     1.00000     0.000000     0.000000   \n",
      "25%       1.00000    -0.693750    10.75000     0.000000     0.000000   \n",
      "50%       1.00000    -0.014500    20.50000     0.500000     0.500000   \n",
      "75%       1.00000     0.656000    30.25000     1.000000     1.000000   \n",
      "max       1.00000     3.802000    40.00000     1.000000     1.000000   \n",
      "\n",
      "                 Y  \n",
      "count  4000.000000  \n",
      "mean      0.059456  \n",
      "std       0.874681  \n",
      "min      -3.053200  \n",
      "25%      -0.538975  \n",
      "50%       0.049150  \n",
      "75%       0.641038  \n",
      "max       3.353800  \n"
     ]
    }
   ],
   "source": [
    "#Y = a + B\n",
    "df[\"Y\"] = 0.85 * df[\"X\"] + 0.61 * (df[\"T\"] * df[\"P\"]) + (-0.17 * df[\"P\"]);\n",
    "print(df.describe());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A         X      Cl         Y     Y*   dd\n",
      "P T                                               \n",
      "0 0  0.802 -0.015810  20.505  0.474444  0.809  0.0\n",
      "  1  0.798 -0.029470  20.495  0.472632  0.790  0.0\n",
      "1 0  0.802 -0.026115  20.505  0.446543  0.599  0.0\n",
      "  1  0.798  0.033542  20.495  0.549666  0.900  1.0\n",
      "     A         X    Cl    T         Y      Y*   dd\n",
      "P                                                 \n",
      "0  0.8 -0.022640  20.5  0.5  0.473538  0.7995  0.0\n",
      "1  0.8  0.003714  20.5  0.5  0.498105  0.7495  0.5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499249\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                     Y*   No. Observations:                 2000\n",
      "Model:                          Logit   Df Residuals:                     1998\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 28 Nov 2022   Pseudo R-squ.:                  0.1131\n",
      "Time:                        17:39:18   Log-Likelihood:                -998.50\n",
      "converged:                       True   LL-Null:                       -1125.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.660e-57\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4013      0.065      6.219      0.000       0.275       0.528\n",
      "T              1.7959      0.124     14.531      0.000       1.554       2.038\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#df[\"Y\"] = df[\"X\"] + df[\"A\"] * (1 - df[\"P\"]) + df[\"T\"] + df[\"A2\"] * df[\"P\"]# - 0.05 * df[\"P\"];\n",
    "\n",
    "#Normalizar Y\n",
    "df[\"Y*\"] = df[\"Y\"];\n",
    "df[\"Y\"] = (df[\"Y\"] - min(df[\"Y\"]))/(max(df[\"Y\"]) - min(df[\"Y\"]));\n",
    "\n",
    "a = 0.58; #Se jugo con estos valores para encontrar las proporciones correctas\n",
    "b = 0.478;\n",
    "c = 0.718;\n",
    "\n",
    "#print(df.describe());\n",
    "df.loc[((df[\"Y\"] < a) & (df[\"P\"]==0) , \"Y*\")] = 1;\n",
    "df.loc[((df[\"Y\"] >= a) & (df[\"P\"]==0) , \"Y*\")] = 0;\n",
    "df.loc[((df[\"Y\"] < b) & (df[\"T\"] == 0) & (df[\"P\"] == 1) , \"Y*\")] = 1;\n",
    "df.loc[((df[\"Y\"] >= b) & (df[\"T\"] == 0) & (df[\"P\"] == 1) , \"Y*\")] = 0;\n",
    "df.loc[((df[\"Y\"] < c) & (df[\"T\"] == 1) & (df[\"P\"] == 1) , \"Y*\")] = 1;\n",
    "df.loc[((df[\"Y\"] >= c) & (df[\"T\"] == 1) & (df[\"P\"] == 1) , \"Y*\")] = 0;\n",
    "\n",
    "#print(df);\n",
    "#print(df.describe());\n",
    "\n",
    "print(df.groupby(by=[\"P\",\"T\"]).mean());\n",
    "print(df.groupby(by=[\"P\"]).mean());\n",
    "\n",
    "#post-test\n",
    "y = df.loc[2000:,\"Y*\"];\n",
    "X = df.loc[2000:,\"T\"];\n",
    "X = sm.add_constant(X);\n",
    "model = sm.Logit(y, X);\n",
    "results = model.fit();\n",
    "print(results.summary());\n",
    "print(results.get_margeff().summary());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Estime el efecto promedio del tratamiento usando pre-post test con la data generada. Muestre que el efecto es equivalente usando ambos metodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500031\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                     Y*   No. Observations:                 4000\n",
      "Model:                          Logit   Df Residuals:                     3996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 28 Nov 2022   Pseudo R-squ.:                 0.06323\n",
      "Time:                        17:43:27   Log-Likelihood:                -2000.1\n",
      "converged:                       True   LL-Null:                       -2135.1\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.082e-58\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4435      0.080     17.944      0.000       1.286       1.601\n",
      "P             -1.0422      0.103    -10.106      0.000      -1.244      -0.840\n",
      "T             -0.1186      0.112     -1.061      0.289      -0.338       0.101\n",
      "dd             1.9145      0.167     11.488      0.000       1.588       2.241\n",
      "==============================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                     Y*\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "==============================================================================\n",
      "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "P             -0.1695      0.016    -10.552      0.000      -0.201      -0.138\n",
      "T             -0.0193      0.018     -1.061      0.289      -0.055       0.016\n",
      "dd             0.3114      0.026     11.970      0.000       0.260       0.362\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#pre-post test\n",
    "df['dd'] = df['P']*df['T'];\n",
    "#df[\"Y\"] = (df[\"X\"] + df[\"A\"] * (1 - df[\"P\"]) + df[\"A2\"] * df[\"P\"] + df[\"dd\"])# - 0.05 * df[\"P\"];\n",
    "\n",
    "#Normalizar Y\n",
    "#df[\"Y\"] = (df[\"Y\"] - min(df[\"Y\"]))/(max(df[\"Y\"]) - min(df[\"Y\"]));\n",
    "\n",
    "y = df['Y*'];\n",
    "X=df[[\"P\",\"T\",\"dd\"]];\n",
    "X = sm.add_constant(X);\n",
    "model = sm.Logit(y, X);\n",
    "results2 = model.fit();\n",
    "print(results2.summary());\n",
    "print(results2.get_margeff().summary());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Estime el efecto ajustando los errores estandar por cluster (la variable grupo representa cada clase). Cual es la diferencia entre ambas estimaciones? Explique porque es esperable (o no) encontrar diferencias entre ambos metodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500031\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                     Y*   No. Observations:                 4000\n",
      "Model:                          Logit   Df Residuals:                     3996\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 28 Nov 2022   Pseudo R-squ.:                 0.06323\n",
      "Time:                        17:29:19   Log-Likelihood:                -2000.1\n",
      "converged:                       True   LL-Null:                       -2135.1\n",
      "Covariance Type:              cluster   LLR p-value:                 3.082e-58\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.4435      0.081     17.889      0.000       1.285       1.602\n",
      "P             -1.0422      0.104    -10.037      0.000      -1.246      -0.839\n",
      "T             -0.1186      0.111     -1.071      0.284      -0.336       0.099\n",
      "dd             1.9145      0.147     13.032      0.000       1.627       2.202\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#clustered standard errors\n",
    "result3 = model.fit(cov_type=\"cluster\", cov_kwds={'groups': df[\"Cl\"]});\n",
    "print(result3.summary());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se supone que es distinto el análisis x cluster que el individual por qué el cluster agrupa las observaciones y saca una medida grupal. Esta medida tiene que etar correlacionada intragrupo, pero no entre grupos. Si no se ajustase el modelo de error, podría obtenerse un error estandar menor, pero equivocado, ya que se trataria  atodos los individuos como iguales pero separados y no como grupos dispares de individuos similares.\n",
    "Se puede notar que el tratamiento no es significativo en la aplicacion a grupos de control, por lo que puede existir correlacion no observada o pérdida de información por la creacion de grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Simule un experimento natural (e.g. intervencion de politica publica) tal que se reduce la proporcion de individuos con 3 hijos o mas que declaran beber alcohol en el tercer periodo a la mitad. Para ello, genere una variable de tratamiento (todos los individuos con mas de 2 hijos son parte de la intervencion), y una nueva variable llamada sdrinlky, talque es identica a drinkly en los periodos 1 y 2 , pero sustituya los valores aleatoriamente en el periodo 3 para generar el efecto esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age      bnrps  cesd  child  dnrps  drinkly  female    hrsusu  hsize  \\\n",
      "0   46   0.000000   6.0      2      0        0       1  0.000000      4   \n",
      "1   48  58.964134   7.0      2      1        0       1  3.891820      4   \n",
      "2   50  60.000130   5.0      2      1        0       1  4.025352      7   \n",
      "3   48   0.000000   0.0      2      0        1       0  4.143135      4   \n",
      "4   50  58.964134   5.0      2      1        1       0  3.891820      4   \n",
      "5   52  60.000130   6.0      2      1        1       0  4.025352      7   \n",
      "6   56   0.000000   6.0      1      0        0       1  0.000000      6   \n",
      "7   60  60.000130   6.0      2      1        0       1  3.178054      4   \n",
      "8   59   0.000000   6.0      1      0        1       0  0.000000      6   \n",
      "9   63  60.000130   6.0      2      1        1       0  3.688879      4   \n",
      "\n",
      "   intmonth  married  nrps  retage  retired  schadj  urban  wave   wealth  \\\n",
      "0         7        1     0      24        0       0      0     1  -5800.0   \n",
      "1         7        1     1      17        0       0      0     2    100.0   \n",
      "2         8        1     1      10        0       0      0     3 -59970.0   \n",
      "3         7        1     0      22        0       4      0     1  -5800.0   \n",
      "4         7        1     1       0        0       4      0     2    100.0   \n",
      "5         8        1     1       0        0       4      0     3 -59970.0   \n",
      "6         8        1     0       0        0       0      0     1    350.0   \n",
      "7         8        1     1       0        0       0      0     3   1400.0   \n",
      "8         8        1     0       0        0       0      0     1    350.0   \n",
      "9         8        1     1       0        0       0      0     3   1400.0   \n",
      "\n",
      "   inid  \n",
      "0     1  \n",
      "1     1  \n",
      "2     1  \n",
      "3     2  \n",
      "4     2  \n",
      "5     2  \n",
      "6     3  \n",
      "7     3  \n",
      "8     4  \n",
      "9     4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporcion:  0.32786885245901637\n",
      "Nueva proporcion:  0.16393442622950818\n",
      "       age      bnrps  cesd  child  dnrps  drinkly  female    hrsusu  hsize  \\\n",
      "0       46   0.000000   6.0      2      0        0       1  0.000000      4   \n",
      "1       48  58.964134   7.0      2      1        0       1  3.891820      4   \n",
      "2       50  60.000130   5.0      2      1        0       1  4.025352      7   \n",
      "3       48   0.000000   0.0      2      0        1       0  4.143135      4   \n",
      "4       50  58.964134   5.0      2      1        1       0  3.891820      4   \n",
      "...    ...        ...   ...    ...    ...      ...     ...       ...    ...   \n",
      "21040   55  87.628258   4.0      4      1        0       1  0.000000      4   \n",
      "21041   57  70.879349   2.0      4      1        1       1  0.000000      3   \n",
      "21042   71  87.628258   3.0      5      1        1       0  0.000000      1   \n",
      "21043   49  87.628258  13.0      4      1        1       1  4.025352      3   \n",
      "21044   60  87.628258   4.0      4      1        0       0  4.025352      3   \n",
      "\n",
      "       intmonth  ...  nrps  retage  retired  schadj  urban  wave   wealth  \\\n",
      "0             7  ...     0      24        0       0      0     1  -5800.0   \n",
      "1             7  ...     1      17        0       0      0     2    100.0   \n",
      "2             8  ...     1      10        0       0      0     3 -59970.0   \n",
      "3             7  ...     0      22        0       4      0     1  -5800.0   \n",
      "4             7  ...     1       0        0       4      0     2    100.0   \n",
      "...         ...  ...   ...     ...      ...     ...    ...   ...      ...   \n",
      "21040         8  ...     1       0        0       0      0     2      0.0   \n",
      "21041         8  ...     1       0        1       0      0     3    900.0   \n",
      "21042         9  ...     0       0        0       4      0     2    600.0   \n",
      "21043         8  ...     1       1        0       4      0     2   5300.0   \n",
      "21044         8  ...     1       0        0       4      0     2   5300.0   \n",
      "\n",
      "        inid  T  sdrinkly  \n",
      "0          1  0         0  \n",
      "1          1  0         0  \n",
      "2          1  0         0  \n",
      "3          2  0         1  \n",
      "4          2  0         1  \n",
      "...      ... ..       ...  \n",
      "21040  25400  1         0  \n",
      "21041  25400  1         1  \n",
      "21042  25401  1         1  \n",
      "21043  25402  1         1  \n",
      "21044  25403  1         0  \n",
      "\n",
      "[21027 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "charls = pd.read_csv(\"charls.csv\");\n",
    "charls.dropna(inplace=True);\n",
    "charls.reset_index(drop=True, inplace=True);\n",
    "\n",
    "drinklys_malos = charls[charls[\"drinkly\"] == \".m\"];\n",
    "drinklys_malos.reset_index(inplace=True);\n",
    "for i in range(len(drinklys_malos)):\n",
    "    charls = charls[charls[\"inid\"] != drinklys_malos['inid'][i]];\n",
    "charls[\"drinkly\"] = charls[\"drinkly\"].astype(int);\n",
    "\n",
    "print(charls.head(10));\n",
    "\n",
    "charls[\"T\"] = 0;\n",
    "charls[\"T\"][charls[\"child\"] > 2] = 1;\n",
    "\n",
    "charls[\"sdrinkly\"] = charls[\"drinkly\"];\n",
    "\n",
    "#Calcular proporcion de drinkly\n",
    "proporcion = sum(charls[\"drinkly\"][charls[\"wave\"] == 3][charls[\"T\"] == 1])/len(charls[\"drinkly\"][charls[\"wave\"] == 3][charls[\"T\"] == 1]);\n",
    "print(\"Proporcion: \", proporcion);\n",
    "nueva_proporcion = proporcion/2;\n",
    "\n",
    "aux = nueva_proporcion * len(charls[\"drinkly\"][charls[\"wave\"] == 3][charls[\"T\"] == 1]);\n",
    "aux2 = np.random.choice([i for i in charls[\"sdrinkly\"][charls[\"sdrinkly\"] == 1][charls[\"wave\"] == 3][charls[\"T\"] == 1].index],int(aux),replace=False);\n",
    "for i in aux2:\n",
    "    charls.loc[i,\"sdrinkly\"] = 0;\n",
    "    \n",
    "proporcion = sum(charls[\"sdrinkly\"][charls[\"wave\"] == 3][charls[\"T\"] == 1])/len(charls[\"sdrinkly\"][charls[\"wave\"] == 3][charls[\"T\"] == 1]);\n",
    "print(\"Nueva proporcion: \", proporcion);\n",
    "print(charls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Estime el efecto del tratamiento usando diferencias en diferencias, comparando entre los periodos 2 y 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.366023410313192, 0.31310344827586206)\n",
      "(0.3700170357751278, 0.16393442622950818)\n",
      "(-0.003993625461935768, 0.14916902204635388)\n",
      "Media: -0.1532\n",
      "(0.48171596757414387, 0.46375605543607207)\n",
      "(0.48280889491734247, 0.3702160587093755)\n",
      "(-0.001092927343198602, 0.09353999672669655)\n",
      "Desviacion Estandar: -0.0946\n"
     ]
    }
   ],
   "source": [
    "#Con medias\n",
    "est_Y_pre = (np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 2]),np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 2]));\n",
    "print(est_Y_pre);\n",
    "est_Y_post = (np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 3]),np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 3]));\n",
    "print(est_Y_post);\n",
    "est_Y = (est_Y_pre[0] - est_Y_post[0],est_Y_pre[1] - est_Y_post[1]);\n",
    "print(est_Y);\n",
    "result = round(est_Y[0] - est_Y[1],4);\n",
    "print(\"Media:\",result);\n",
    "\n",
    "#Con desviacion estandar\n",
    "est_Y_pre = (np.std(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 2]),np.std(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 2]));\n",
    "print(est_Y_pre);\n",
    "est_Y_post = (np.std(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 3]),np.std(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 3]));\n",
    "print(est_Y_post);\n",
    "est_Y = (est_Y_pre[0] - est_Y_post[0],est_Y_pre[1] - est_Y_post[1]);\n",
    "print(est_Y);\n",
    "result2 = round(est_Y[0] - est_Y[1],4);\n",
    "print(\"Desviacion Estandar:\",result2);\n",
    "\n",
    "#Como la media (-0.1532) no es mas de dos veces mayor a la desviacion (-0.0946), entonces no existe una diferencia \n",
    "#significativa entre las personas que reciben y que no reciben tratamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Compare el efecto del tratamiento generando grupos pseudo-equivalentes, en particular entre individuos solo con 3 hijos (tratamiento) y 2 hijos (control)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3637137989778535, 0.3300110741971207)\n",
      "(0.3693998309382925, 0.17204932472108045)\n",
      "(-0.005686031960438986, 0.15796174947604028)\n",
      "Media: -0.1636\n",
      "(0.4810676370438526, 0.4702167214214981)\n",
      "(0.48264230631084565, 0.3774233095399672)\n",
      "(-0.0015746692669930673, 0.0927934118815309)\n",
      "Desviacion Estandar: -0.0944\n"
     ]
    }
   ],
   "source": [
    "#Con medias\n",
    "est_Y_pre = (np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 2][charls[\"child\"] == 2]),np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 2][charls[\"child\"] == 3]));\n",
    "print(est_Y_pre);\n",
    "est_Y_post = (np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 3][charls[\"child\"] == 2]),np.mean(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 3][charls[\"child\"] == 3]));\n",
    "print(est_Y_post);\n",
    "est_Y = (est_Y_pre[0] - est_Y_post[0],est_Y_pre[1] - est_Y_post[1]);\n",
    "print(est_Y);\n",
    "result = round(est_Y[0] - est_Y[1],4);\n",
    "print(\"Media:\",result);\n",
    "\n",
    "#Con desviacion estandar\n",
    "est_Y_pre = (np.std(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 2][charls[\"child\"] == 2]),np.std(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 2][charls[\"child\"] == 3]));\n",
    "print(est_Y_pre);\n",
    "est_Y_post = (np.std(charls[\"sdrinkly\"][charls[\"T\"] == 0][charls[\"wave\"] == 3][charls[\"child\"] == 2]),np.std(charls[\"sdrinkly\"][charls[\"T\"] == 1][charls[\"wave\"] == 3][charls[\"child\"] == 3]));\n",
    "print(est_Y_post);\n",
    "est_Y = (est_Y_pre[0] - est_Y_post[0],est_Y_pre[1] - est_Y_post[1]);\n",
    "print(est_Y);\n",
    "result2 = round(est_Y[0] - est_Y[1],4);\n",
    "print(\"Desviacion Estandar:\",result2);\n",
    "\n",
    "#Como la media (-0.1636) no es mas de dos veces mayor a la desviacion (-0.0944), entonces no existe una diferencia \n",
    "#significativa entre las personas que reciben y que no reciben tratamiento para ese numero de hijos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Estime el efecto anterior usando la variable married como instrumento para determinar el efecto del tratamiento en la pregunta 12. Como se interpreta el efecto en este caso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomando la variable married como elemento exógeno para la asignación del tratamiento y no dejar aleatorizar como en el experimento simple original.  [si se puede hacer un test de correlación de la variable con el tratamiento]. Así, se puede atacar al tratamiento en sí sin afectar directamente el outcome ni el error por componente no observado. \n",
    "Se hace la misma tabla de interceptor de los factores, para los datos antes y después del tratamiento. La diferencia al interpretar estos datos va con el hecho de que se pierde un gran valor de aleatoriedad, al tener un instrumento que seleccione una muestra. Además se tiene que entender que muchas de las personas no reaccionan al instrumento, o actuarán distinto debido a él. Como además, el modelo de mínimos cuadrados no especifica correctamente el modelo con variables instrumentales que correlacionen el error estándar, se hace el uso de mínimos cuadrados en dos etapas. Se asume que married está correlacionado con la variable dependiente, pero no con el error.\n",
    "Suponiendo que se emplea un mínimo cuadrados por etapas, debemos hacer dos ecuaciones, una representando al estimador de toma de alcohol por periodo según retardos de la variable (regresor endógeno ) y otra para el error no observado con una variable de ruido adicional. \n",
    "La interceptación desde acá se vuelve similar, se analiza por mco el regresor endógeno y luego el resultado al modelo inicial. Ahí, se analizará si el coeficiente del regresor será consistente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Finalmente, asuma que la intervencion se implementa en todos los individuos. Genere una nueva variable de tratamiento un nueva variable llamada tdrinkly donde el efecto es una reduccion de 50% en la prevalencia de consumo de alcohol en toda la poblacion en el tercer periodo (identica a drinkly en los periodos 1 y 2). Genere una variable cdrinkly que es identica a drinkly en los periodos 1 y 2 y use la informacion de ambos periodos para predicir el valor esperado de drinkly en el tercer periodo, estos seran los valores de cdrinkly en el periodo 3 (contrafactual). Finalmente, estime el efecto de la intervencion en toda la poblacion comparando entre tdrinkly (datos reales) versus cdrinkly contrafactual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporcion:  0.34792477302204927\n",
      "Nueva proporcion:  0.17396238651102464\n"
     ]
    }
   ],
   "source": [
    "charls[\"tdrinkly\"] = charls[\"drinkly\"]; \n",
    "\n",
    "proporcion = sum(charls[\"drinkly\"][charls[\"wave\"] == 3])/len(charls[\"drinkly\"][charls[\"wave\"] == 3]);\n",
    "print(\"Proporcion: \", proporcion);\n",
    "nueva_proporcion = proporcion/2;\n",
    "\n",
    "aux = nueva_proporcion * len(charls[\"drinkly\"][charls[\"wave\"] == 3]);\n",
    "aux2 = np.random.choice([i for i in charls[\"tdrinkly\"][charls[\"tdrinkly\"] == 1][charls[\"wave\"] == 3].index],int(aux),replace=False);\n",
    "for i in aux2:\n",
    "    charls.loc[i,\"tdrinkly\"] = 0;\n",
    "    \n",
    "proporcion = sum(charls[\"tdrinkly\"][charls[\"wave\"] == 3])/len(charls[\"tdrinkly\"][charls[\"wave\"] == 3]);\n",
    "print(\"Nueva proporcion: \", proporcion);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.519034\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                drinkly   No. Observations:                14859\n",
      "Model:                          Logit   Df Residuals:                    14843\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Mon, 28 Nov 2022   Pseudo R-squ.:                  0.1826\n",
      "Time:                        19:56:58   Log-Likelihood:                -7712.3\n",
      "converged:                       True   LL-Null:                       -9435.6\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1822      0.216      0.845      0.398      -0.241       0.605\n",
      "age           -0.0056      0.003     -1.918      0.055      -0.011       0.000\n",
      "bnrps          0.0003      0.001      0.517      0.605      -0.001       0.002\n",
      "cesd          -0.0025      0.003     -0.732      0.464      -0.009       0.004\n",
      "child          0.0213      0.017      1.278      0.201      -0.011       0.054\n",
      "dnrps          0.0275      0.078      0.353      0.724      -0.125       0.180\n",
      "female        -2.0467      0.046    -44.856      0.000      -2.136      -1.957\n",
      "hrsusu         0.1224      0.017      7.296      0.000       0.090       0.155\n",
      "hsize         -0.0287      0.011     -2.570      0.010      -0.051      -0.007\n",
      "married        0.0021      0.066      0.031      0.975      -0.128       0.132\n",
      "nrps           0.0196      0.056      0.348      0.728      -0.091       0.130\n",
      "retage         0.0115      0.005      2.404      0.016       0.002       0.021\n",
      "retired       -0.2889      0.079     -3.670      0.000      -0.443      -0.135\n",
      "schadj         0.0147      0.006      2.310      0.021       0.002       0.027\n",
      "urban          0.0161      0.051      0.313      0.754      -0.085       0.117\n",
      "wealth      1.769e-07   4.17e-07      0.424      0.672   -6.41e-07    9.94e-07\n",
      "==============================================================================\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                drinkly\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "==============================================================================\n",
      "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "age           -0.0010      0.001     -1.919      0.055      -0.002    2.08e-05\n",
      "bnrps       5.417e-05      0.000      0.517      0.605      -0.000       0.000\n",
      "cesd          -0.0004      0.001     -0.732      0.464      -0.002       0.001\n",
      "child          0.0037      0.003      1.278      0.201      -0.002       0.009\n",
      "dnrps          0.0047      0.013      0.353      0.724      -0.022       0.031\n",
      "female        -0.3532      0.006    -61.511      0.000      -0.364      -0.342\n",
      "hrsusu         0.0211      0.003      7.342      0.000       0.015       0.027\n",
      "hsize         -0.0050      0.002     -2.572      0.010      -0.009      -0.001\n",
      "married        0.0004      0.011      0.031      0.975      -0.022       0.023\n",
      "nrps           0.0034      0.010      0.348      0.728      -0.016       0.022\n",
      "retage         0.0020      0.001      2.405      0.016       0.000       0.004\n",
      "retired       -0.0499      0.014     -3.676      0.000      -0.076      -0.023\n",
      "schadj         0.0025      0.001      2.311      0.021       0.000       0.005\n",
      "urban          0.0028      0.009      0.313      0.754      -0.015       0.020\n",
      "wealth      3.053e-08    7.2e-08      0.424      0.672   -1.11e-07    1.72e-07\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "charls[\"cdrinkly\"] = charls[\"drinkly\"];\n",
    "\n",
    "y = charls['drinkly'][charls['wave'] <= 2];\n",
    "X = charls[['age','bnrps','cesd','child','dnrps',\n",
    "           'female','hrsusu','hsize','married','nrps',\n",
    "           'retage','retired','schadj','urban','wealth']][charls['wave'] <= 2];\n",
    "X = sm.add_constant(X);\n",
    "model = sm.Logit(y, X);\n",
    "results2 = model.fit();\n",
    "print(results2.summary());\n",
    "print(results2.get_margeff().summary());"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
